- name: nfcore_taxtriage
  title: "TaxTriage"
  icon: "virus"
  version: 1.0
  basestack_released: 2.0
  module: True
  url: https://nf-co.re/viralrecon
  # description: "nf-core/viralrecon is a bioinformatics analysis pipeline used to perform assembly and intra-host/low-frequency variant calling for viral samples."
  tags: 
    - "Nextflow"
    - "metagenomics"
    - "Nanopore"
    - "Illumina"
  shared:
    services:
      orchestrator:
        label: "Orchestrator"
        name: "orchestrator"
        image: "jhuaplbio/basestack_orchestrator:v1.0.0"
        workingdir: "/opt/data"
        orchestrated: false #orchestrated means it r
        init: false
        orchestrator: true
        force_restart: false
        continuous: true
        force_init: false
        command: []
  procedures: 
    - name: nfcore_taxtriage #Top level is the left-hand selection of the menu and the major module to install 
      title: "TaxTriage"
      icon: "virus"
      module: True
      init: false 
      dependencies:
        - target: "jhuaplbio/basestack_orchestrator:v1.0.0"
          label: jhuaplbio/basestack_orchestrator
          type: "docker-local"
          build: 
            path: ${configPath}/modules/orchestrator/Dockerfile
            file: Dockerfile
          format: "dockerfile"
        - target: "basestack-docker-taxtriage"
          label: "TaxTriage Volume"
          type: "volume"
        - source:
            url: ftp.ccb.jhu.edu
            type: file
            user: anonymous
            path: /pub/data/kraken2_dbs/old/minikraken2_v2_8GB_201904.tgz
            password: null
            protocol: ftp
            remove: false
            target: "${writePath}/workflows/taxtriage/minikraken2.tar.gz"
          label: Minikraken2
          type: download
          format: dir
          decompress:
            format: tgz
            source: "${writePath}/workflows/taxtriage/minikraken2.tar.gz"
          target: "${writePath}/workflows/taxtriage/minikraken2_v2_8GB_201904_UPDATE"
          overwrite: true
      tags: 
        - "Nextflow"
        - "metagenomics"
        - "nanopore"
        - "illumina"
      variables:
        maxCPUs:
          label: "Maximum CPUs"
          element: "number"
          source: 3
          optional: true
          target: "%{variables.maxCPUs.source}"
          append:
            command: " --max_cpus \"${maxCPUs}\" "
            placement: 2
            position: "end"
            services: 
              - 1
        maxMemory:
          label: "Maximum Memory (GB)"
          element: "number"
          source: 7
          optional: true
          target: "%{variables.maxMemory.source}"
          append:
            command: " --max_memory \"${maxMemory}\"GB "
            placement: 2
            position: "end"
            services: 
              - 1
        db:
          label: Classifier database
          class: wb-100 p-3 mb-1
          option: 0
          options:
            - element: null
              name: Minikraken2
              source: "${writePath}/workflows/taxtriage/minikraken2_v2_8GB_201904_UPDATE"
              target: /opt/databases/minikraken2
              warning: >-
                Requires roughly 7.5 GB of free RAM to load. If limited in RAM
                available, try to change Memory Mapping below to classify on the
                local filesystem. If your input file is large, however, this can
                take a long time
              bind:
                from: '%{variables.db.source}'
                to: /opt/databases/minikraken2
            - element: dir
              name: Custom DB
              source: null
              target: /opt/databases/<<basename(%{variables.db.source})>>
              bind: self
        codedir: 
          label: "Code Directory"
          element: "dir"
          source: null
          hint: "Directory containing your offline source code"
          target: "/opt/code"
          bind: "self"
        skip_plots:
          label: "Skip QC Plotting"
          element: "checkbox"
          source: true
          hint: "Skip QC plotting"
          define: 
            skip_plots: "--skip_plots"
        resume:
          label: "Resume Nextflow"
          element: "checkbox"
          source: true
          hint: "pick up where you left off, useful if piplines are lenghty or you're debugging issues with a failed midrun submission"
          define: 
            resume: "-resume"
        assembly: 
          label: "Assembly File"
          element: "file"
          source: null
          hint: "File containing assembly refseq"
          target: "/opt/assembly/<<basename(%{variables.assembly.source})>>"
          bind: "directory"
        filter_db:
          label: "Filter Database"
          element: "dir"
          source: null
          hint: "Database to extract reads out of"
          target: "/opt/database_filter"
          bind: "self"
          define:
            filter: " --filter %{variables.filter_db.target} "
        rundir:
          label: "Run Directory"
          element: "file"
          source: null
          hint: "Requires a Samplesheet.csv with all relevant data in the same folder in terms of pathing as well as things like your fastq files and sequencing summary files"
          target: "/opt/data"
          bind: "self"
        samplesheet:
            label: "Samplesheet"
            warning: "Must be in the root (same level) of the run directory"
            hint: "File that contains metadata for all of your sequences in the run such as timestamp of creation. Must be in root level of your run directory. "
            element: "exists"
            source:  null
            validations:
              - type: "files"
                error: "Must have a Samplesheet.csv file in the root directory (directly in your run directory)"
                target: 
                  type: "value"
                  minimum: 1
                  path: "%{variables.rundir.source}"
                  value: "Samplesheet.csv$"
            update_on: 
              depends:
                - rundir
              action: "exists"
              source: "%{variables.rundir.source}"
        # fastqs:
        #   label: "Input Reads"
        #   hint: "Folder(s) that contains 1 or more fastq files in COMPRESSED (.gz) format"
        #   class: "wb-50  p-3 mb-1"
        #   warning: "Ensure that all fastq files you want to analyze are compressed"
        #   update_on: 
        #       depends:
        #         - rundir
        #       action: "exists"
        #       source: "%{variables.rundir.source}/*"
        #   validations:
        #     - type: "files"
        #       error: "Must have 1 or more .fastq.gz files"
        #       target: 
        #         type: "value"
        #         minimum: 1
        #         path: "%{variables.rundir.source}"
        #         value: ".*(fastq|fq).gz"
        profile:
          label: "Profile"
          options:
            - "docker"
            - "singularity"
            - "conda"
        outdir:
          label: "Output Directory"
          output: True
          hint: "Directory to place your analysis results into"
          source: "%{variables.rundir.source}/taxtriage_output"
          path: "%{variables.rundir.source}/taxtriage_output"
          name: "Output Folder"
          target: "/opt/output"
          bind: "self"
      services:
        - name: taxtriage
          orchestrator: true
          force_restart: false
          continuous: true
          force_init: false
          label: "TaxTriage"
          image: "jhuaplbio/basestack_orchestrator:v1.0.0"
          workingdir: "/opt/data"
          warning: "This process requires internet in its current state"
          command: [
            "bash", "-c", "parallel --ungroup ::: dockerd-entrypoint.sh  'sleep 5; nextflow run /opt/code/main.nf 
              --input /opt/data/Samplesheet.csv
              --db ${db}  
              --outdir /opt/output
              --max_memory ${maxMemory}GB --max_cpus ${maxCPUs} 
              -profile ${profile} ${skip_plots}
              --assembly ${assembly} --demux 
              ${resume} ${filter};pkill -9 -u $(id -u) ';  "
          ]
    